from keras.engine.training import Model
import keras
from keras.optimizer_v2 import learning_rate_schedule
import numpy as np
#from keras.datasets import imdb
from keras.models import Sequential
from keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import ParameterGrid
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.sequence import pad_sequences

vocab_size = 5000 
maximum_sequence_length = 500
embedding_dim = 16

(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words= vocab_size)

X_train, X_val ,X_test = X_train[:-10000], X_train[-10000:-5000],X_train[-5000:]
y_train, y_val ,y_test = y_train[:-10000], y_train[-10000:-5000],y_train[-5000:]

X_train = pad_sequences(X_train, maxlen= maximum_sequence_length)
X_val = pad_sequences(X_val, maxlen= maximum_sequence_length)
X_test = pad_sequences(X_test, maxlen= maximum_sequence_length)

print('X_train shape:', X_train.shape)
print('X_val shape:', X_val.shape)
print('X_test shape:', X_test.shape)


def create_model(filters = 64, kernel_size = (3,3), strides=1, units = 256,optimizer='adam', rate = 0.25):
    model = Sequential()
    # First Convolutional Layer(s)
    model.add(Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu', input_shape=))
    model.add(MaxPooling2D((2,2)))
    # Second Convolutional Layer(s)
    model.add(Conv2D(filters = filters, kernel_size = kernel_size, strides= strides, padding='same', activation= 'relu'))
    model.add(MaxPooling2D((2,2)))
    # Third Convolutional Layer(s)
    model.add(Conv2D(filters = filters, kernel_size = kernel_size, strides= strides, padding='same', activation= 'relu'))

    # Dense layer(s)
    model.add(Dense(units = units, activation= 'relu'))
    model.add(Dropout(rate))
    # Output layer
    model.add(Dense(1, activation= 'sigmoid'))
    
    # Compile the model
    model.compile(loss='binary_crossentropy',
                  optimizer= optimizer,
                  metrics=['accuracy'])
    return model
# Build the model
model = KerasClassifier(build_fn= create_model)

filters = [32,128]
kernel_size = [3,5]
strides= [1]
Dense_units = [128,512]
rate_dropouts = [0.25]
optimizers = ['adam']
epochs = [5]
batches = [2,16]
# ----------------------------------------------
param_grid = dict(optimizer= optimizers, epochs= epochs,
                  batch_size= batches,filters = filters,
                  kernel_size = kernel_size, strides = strides,
                  units = Dense_units, rate = rate_dropouts)

grid = ParameterGrid(param_grid)
param_sets = list(grid)

param_scores = []
for params in grid:
    print(params)
    model.set_params(**params)
    learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy',
                                                patience=2,verbose=1,
                                                factor=0.5,min_lr=0.00001)
    history = model.fit(X_train, y_train,
                        shuffle= True,
                        callbacks =learning_rate_reduction)
    param_score = history.history['accuracy']
    param_scores.append(param_score[-1])
    print('-'*100) 

print('param_scores:', param_scores)
p = np.argmax(np.array(param_scores))
print("best score:", param_scores[p])
best_params = param_sets[p]
print("best parameter set", best_params)
model.set_params(**best_params)
model.fit(np.vstack((X_train, X_val)), np.hstack((y_train, y_val)))
result = model.score(X_test, y_test)
print("Test accuracy =" + str(result*100) +"%" )
